# 知识图谱的全文检索技术实施方案

## 1. 技术架构设计

本方案基于当前项目的技术栈（Python/Flask 后端 + React 前端 + NebulaGraph 图数据库）以及文档 `本地知识图谱应用与全文检索的实现方案.md` 中提出的 GraphRAG 理念，构建一套融合全文检索与知识图谱的智能检索系统。

### 1.1 系统架构概览

系统采用微服务架构思想，分为数据层、知识层、检索层和应用层。

```mermaid
graph TD
    User[用户] --> WebUI[React 前端应用]
    WebUI --> APIGateway[API 网关 / Nginx]
    
    subgraph "应用服务层 (Flask Backend)"
        APIGateway --> SearchAPI[检索服务 API]
        APIGateway --> KGAPI[图谱管理 API]
        APIGateway --> AdminAPI[系统管理 API]
        
        SearchAPI --> IntentAnalysis[意图识别模块]
        SearchAPI --> QueryBuilder[查询构建模块]
        SearchAPI --> RAGEngine[RAG 增强引擎]
    end
    
    subgraph "知识处理层 (Celery Workers)"
        DocIngest[文档摄入服务]
        NLPProcess[NLP 处理服务]
        KGBuilder[图谱构建服务]
        VectorEncoder[向量编码服务]
    end
    
    subgraph "数据存储层"
        MinIO[MinIO 文件存储]
        ES[Elasticsearch 全文索引]
        Milvus[Milvus/Faiss 向量库]
        Nebula[NebulaGraph 图数据库]
        Redis[Redis 缓存/队列]
    end
    
    AdminAPI --> DocIngest
    DocIngest --> Redis
    Redis --> NLPProcess
    NLPProcess --> KGBuilder
    NLPProcess --> VectorEncoder
    
    KGBuilder --> Nebula
    VectorEncoder --> Milvus
    NLPProcess --> ES
    DocIngest --> MinIO
    
    QueryBuilder --> ES
    QueryBuilder --> Nebula
    QueryBuilder --> Milvus
    
    RAGEngine --> LLM[LLM 服务 (本地/API)]
```

### 1.2 核心数据流程

1.  **文档摄入与处理流程**：
    *   用户上传文档 -> MinIO 存储 -> 触发 Celery 任务。
    *   **文本提取**：解析 PDF/Word/TXT，提取纯文本。
    *   **分块 (Chunking)**：基于语义或固定长度对文本进行切片。
    *   **向量化**：调用 Embedding 模型将文本块转化为向量 -> 存入 Milvus。
    *   **全文索引**：将文本块存入 Elasticsearch，建立倒排索引。
    *   **知识抽取**：利用 LLM 或 NLP 模型提取实体 (Entity) 和关系 (Relation)。
    *   **图谱构建**：将实体和关系写入 NebulaGraph，并建立实体与文本块的关联。

2.  **混合检索流程 (GraphRAG)**：
    *   用户输入查询 -> 意图识别 (判断是事实型、关系型还是全文型)。
    *   **并行检索**：
        *   **全文检索**：Elasticsearch 关键词匹配。
        *   **向量检索**：Milvus 语义相似度匹配。
        *   **图谱检索**：NebulaGraph 多跳查询、路径发现。
    *   **重排序 (Rerank)**：结合相关性得分对多路召回结果进行融合排序。
    *   **上下文构建**：提取相关文本块 + 关联子图结构。
    *   **LLM 生成**：将上下文注入 Prompt，生成最终回答。

---

## 2. 具体实现步骤

### 2.1 知识图谱构建 (Knowledge Graph Construction)

**技术选型**：
*   **图数据库**：NebulaGraph v3.8.0
*   **抽取模型**：基于 LLM (如 GPT-4, DeepSeek) 的 Few-shot Prompting 或微调后的 BERT/BiLSTM-CRF 模型。
*   **NLP 工具**：Spacy / HanLP (中文处理)。

**实现方法**：
1.  **Schema 定义**：
    *   在 NebulaGraph 中定义 Tag (如 `Person`, `Company`, `Document`, `Concept`) 和 Edge Type (如 `INVEST`, `AUTHOR_OF`, `MENTIONS`)。
    *   建立 `Document` -> `Chunk` -> `Entity` 的层级结构。
2.  **实体与关系抽取**：
    *   设计 Prompt 让 LLM 从文本块中输出 JSON 格式的三元组 `(Subject, Predicate, Object)`。
    *   示例 Prompt：*"请分析以下文本，提取其中的实体和关系，输出为 JSON 列表..."*
3.  **实体对齐与融合**：
    *   利用文本相似度 (Levenshtein distance) 和向量相似度对同名或近义实体进行合并 (Entity Resolution)。
    *   建立实体别名库 (Alias Mapping)。

### 2.2 全文检索与向量检索系统

**技术选型**：
*   **全文引擎**：Elasticsearch 8.x (支持中文分词插件 ik_max_word)。
*   **向量数据库**：Milvus 或 FAISS (轻量级)。
*   **Embedding 模型**：BGE-M3 (支持多语言、长文本) 或 text2vec-base-chinese。

**实现策略**：
1.  **混合索引策略**：
    *   Elasticsearch 中存储文档的元数据 (Title, Date, Author) 和 Content。
    *   Milvus 中存储 Content 的 Embedding 向量，ID 与 ES 中的文档 ID 保持一致。
2.  **数据同步**：
    *   使用 Logstash 或自定义 Python 脚本保证 ES 和 Milvus 数据的一致性。

### 2.3 接口设计与模块集成

**后端接口 (Flask-RESTX)**：

*   `POST /api/v1/documents/upload`: 上传文件，触发处理流程。
*   `POST /api/v1/search/query`: 统一检索接口。
    *   参数：`query` (文本), `mode` (hybrid/vector/graph/text), `filters` (筛选条件)。
    *   返回：`answer` (LLM 生成), `sources` (引用文档), `graph_data` (相关子图 JSON)。
*   `GET /api/v1/graph/explore`: 图谱探索接口，返回节点和边数据供前端可视化。

**前端集成 (React)**：
*   使用 `React Flow` 或 `AntV G6` 渲染 `graph_data`。
*   使用 `Markdown` 渲染 LLM 生成的回答，并支持点击引用跳转到源文档。

---

## 3. 开发计划

### 3.1 阶段一：基础架构搭建与全文/向量检索 (Week 1-2)
*   **目标**：完成文档上传、解析、向量化存储和基础问答。
*   **任务**：
    *   部署 Elasticsearch, Milvus, MinIO, Redis。
    *   实现文档解析服务 (Text Extraction)。
    *   实现向量化与存入 Milvus。
    *   开发基础 RAG 接口 (仅向量检索)。

### 3.2 阶段二：知识图谱构建与存储 (Week 3-4)
*   **目标**：实现知识抽取，构建 NebulaGraph 图谱。
*   **任务**：
    *   部署 NebulaGraph。
    *   设计图谱 Schema。
    *   开发基于 LLM 的实体关系抽取模块。
    *   实现图谱写入与实体对齐逻辑。

### 3.3 阶段三：GraphRAG 混合检索实现 (Week 5-6)
*   **目标**：融合图谱检索与向量检索，提升问答准确率。
*   **任务**：
    *   开发图谱检索算法 (如子图提取、最短路径)。
    *   实现混合检索重排序逻辑 (Rerank)。
    *   优化 LLM Prompt，注入图谱上下文。

### 3.4 阶段四：前端可视化与系统优化 (Week 7-8)
*   **目标**：完善 UI/UX，进行性能测试与调优。
*   **任务**：
    *   开发知识图谱可视化交互界面。
    *   实现检索结果的溯源展示。
    *   系统集成测试与性能压测。

**资源需求**：
*   后端开发：2人
*   前端开发：1人
*   算法/NLP：1人
*   计算资源：GPU 服务器 (用于 Embedding 和 LLM 推理，或调用外部 API)。

---

## 4. 测试验证方案

### 4.1 功能测试用例

| 模块 | 测试点 | 预期结果 |
| :--- | :--- | :--- |
| **文档处理** | 上传 PDF/Word 文档 | 解析成功，文本块存入 ES 和 Milvus，无乱码。 |
| **知识构建** | 文本包含明确关系 "A 是 B 的子公司" | NebulaGraph 中生成 Edge: `(A)-[:SUBSIDIARY]->(B)`。 |
| **混合检索** | 查询实体关系类问题 | 能够返回准确的关系描述，优于纯向量检索。 |
| **图谱探索** | 前端查询特定节点 | 展示该节点及其一跳/两跳邻居节点。 |

### 4.2 性能测试

*   **指标**：
    *   **文档处理速度**：< 5秒/页 (纯文本处理)。
    *   **检索响应时间**：P95 < 2秒 (包含检索 + Rerank，不含 LLM 生成)。
    *   **并发支持**：支持 50 QPS。
*   **方法**：使用 Locust 或 JMeter 进行压力测试，模拟多用户并发搜索。

### 4.3 质量验收标准

1.  **准确性**：在测试数据集 (Golden Dataset) 上，GraphRAG 的回答准确率 (Factuality) 需优于 Baseline (纯 Vector RAG) 10% 以上。
2.  **稳定性**：系统连续运行 24 小时无 Crash，服务可用性 > 99.9%。
3.  **完整性**：所有设计文档中的功能模块均已实现，且有对应的单元测试覆盖。
